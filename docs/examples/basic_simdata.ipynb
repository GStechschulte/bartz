{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --no-deps bartz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAIYdaOqXP5g",
        "outputId": "22e6fbe4-7a21-44ca-c039-441cfceebd97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bartz\n",
            "  Downloading bartz-0.4.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Downloading bartz-0.4.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: bartz\n",
            "Successfully installed bartz-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell tells JAX to use all and only 95% of the GPU memory:"
      ],
      "metadata": {
        "id": "jfDOl1RlfoKx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n3kjX0pvXOWc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.95'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell defines the data generating process (DGP) $$y_i=\\frac 1{\\text{norm.}} \\sum_{j=1}^p X_{ij} \\beta_j + \\frac 1{\\text{norm.}} \\sum_{j=1}^p \\sum_{k=1}^p A_{jk} X_{ij} X_{ik} + \\varepsilon_i,$$ where the matrix $A$ is sparse."
      ],
      "metadata": {
        "id": "kN-fpqLVfz-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from jax import random\n",
        "\n",
        "@functools.partial(jax.jit, static_argnums=(1, 2))\n",
        "def dgp(key, n, p, max_interactions, error_sdev):\n",
        "    \"\"\" DGP. Uses data-based standardization, so you have to generate train &\n",
        "    test at once. \"\"\"\n",
        "\n",
        "    # split random key\n",
        "    keys = list(random.split(key, 4))\n",
        "\n",
        "    # generate matrices\n",
        "    X = random.uniform(keys.pop(), (p, n))\n",
        "    beta = random.normal(keys.pop(), (p,))\n",
        "    A = random.normal(keys.pop(), (p, p))\n",
        "    error = random.normal(keys.pop(), (n,))\n",
        "\n",
        "    # make A banded to limit the number of interactions\n",
        "    num_nonzero = 1 + (max_interactions - 1) // 2\n",
        "    num_nonzero = jnp.clip(num_nonzero, 0, p)\n",
        "    interaction_pattern = jnp.arange(p) < num_nonzero\n",
        "    multi_roll = jax.vmap(jnp.roll, in_axes=(None, 0))\n",
        "    nonzero = multi_roll(interaction_pattern, jnp.arange(p))\n",
        "    A *= nonzero\n",
        "\n",
        "    # compute terms\n",
        "    linear = beta @ X\n",
        "    quadratic = jnp.einsum('ai,bi,ab->i', X, X, A)\n",
        "    error *= error_sdev\n",
        "\n",
        "    # equalize the terms\n",
        "    linear /= jnp.std(linear)\n",
        "    quadratic /= jnp.std(quadratic)\n",
        "\n",
        "    # compute response\n",
        "    y = linear + quadratic + error\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "WoxELDG6Xbbn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell defines a convenience function that generates the data and splits it in train/test sets."
      ],
      "metadata": {
        "id": "oNSvjWAVV7M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "Data = collections.namedtuple('Data', 'X_train y_train X_test y_test')\n",
        "\n",
        "def make_synthetic_dataset(key, n_train, n_test, p, sigma):\n",
        "    X, y = dgp(key, n_train + n_test, p, 5, sigma)\n",
        "    X_train, y_train = X[:, :n_train], y[:n_train]\n",
        "    X_test, y_test = X[:, n_train:], y[n_train:]\n",
        "    return Data(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "ysQGFM0UV6o-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next generates the data and runs BART."
      ],
      "metadata": {
        "id": "WtoDbUNDKFgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import bartz\n",
        "\n",
        "n_train = 100_000  # number of training points\n",
        "p = 1000           # number of predictors/features\n",
        "sigma = 0.1        # error standard deviation\n",
        "\n",
        "n_test = 1000      # number of test points\n",
        "n_tree = 10_000    # number of trees used by bartz\n",
        "\n",
        "# seeds for random sampling\n",
        "keys = list(random.split(random.key(202404161853), 2))\n",
        "\n",
        "# generate the data on CPU to avoid running out of GPU memory\n",
        "cpu = jax.devices('cpu')[0]\n",
        "key = jax.device_put(keys.pop(), cpu) # the random key is the only jax-array input, so it determines the device used\n",
        "data = make_synthetic_dataset(key, n_train, n_test, p, sigma)\n",
        "\n",
        "# move the data to GPU (if there is a GPU)\n",
        "device = jax.devices()[0] # the default jax device is gpu if there is one\n",
        "data = jax.device_put(data, device)\n",
        "\n",
        "# run bartz\n",
        "start = time.perf_counter()\n",
        "bart = bartz.BART.gbart(data.X_train, data.y_train, ntree=n_tree, printevery=10, seed=keys.pop())\n",
        "end = time.perf_counter()"
      ],
      "metadata": {
        "id": "hFK9jGWdJ8aH",
        "outputId": "24db24eb-0c68-4e92-9a6b-ccd2c5ec54a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration   10/1100 P_grow=0.54 P_prune=0.46 A_grow=0.25 A_prune=0.29 (burnin)\n",
            "Iteration   20/1100 P_grow=0.55 P_prune=0.45 A_grow=0.23 A_prune=0.28 (burnin)\n",
            "Iteration   30/1100 P_grow=0.55 P_prune=0.45 A_grow=0.22 A_prune=0.25 (burnin)\n",
            "Iteration   40/1100 P_grow=0.53 P_prune=0.47 A_grow=0.21 A_prune=0.23 (burnin)\n",
            "Iteration   50/1100 P_grow=0.53 P_prune=0.47 A_grow=0.21 A_prune=0.25 (burnin)\n",
            "Iteration   60/1100 P_grow=0.54 P_prune=0.46 A_grow=0.21 A_prune=0.26 (burnin)\n",
            "Iteration   70/1100 P_grow=0.54 P_prune=0.46 A_grow=0.21 A_prune=0.23 (burnin)\n",
            "Iteration   80/1100 P_grow=0.54 P_prune=0.46 A_grow=0.20 A_prune=0.24 (burnin)\n",
            "Iteration   90/1100 P_grow=0.54 P_prune=0.46 A_grow=0.20 A_prune=0.23 (burnin)\n",
            "Iteration  100/1100 P_grow=0.54 P_prune=0.45 A_grow=0.20 A_prune=0.23 (burnin)\n",
            "Iteration  110/1100 P_grow=0.54 P_prune=0.46 A_grow=0.20 A_prune=0.22\n",
            "Iteration  120/1100 P_grow=0.54 P_prune=0.46 A_grow=0.19 A_prune=0.23\n",
            "Iteration  130/1100 P_grow=0.53 P_prune=0.47 A_grow=0.18 A_prune=0.21\n",
            "Iteration  140/1100 P_grow=0.54 P_prune=0.46 A_grow=0.19 A_prune=0.22\n",
            "Iteration  150/1100 P_grow=0.53 P_prune=0.47 A_grow=0.19 A_prune=0.22\n",
            "Iteration  160/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.22\n",
            "Iteration  170/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.21\n",
            "Iteration  180/1100 P_grow=0.54 P_prune=0.46 A_grow=0.19 A_prune=0.22\n",
            "Iteration  190/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.21\n",
            "Iteration  200/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.22\n",
            "Iteration  210/1100 P_grow=0.54 P_prune=0.46 A_grow=0.19 A_prune=0.21\n",
            "Iteration  220/1100 P_grow=0.53 P_prune=0.47 A_grow=0.18 A_prune=0.21\n",
            "Iteration  230/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.21\n",
            "Iteration  240/1100 P_grow=0.53 P_prune=0.47 A_grow=0.18 A_prune=0.21\n",
            "Iteration  250/1100 P_grow=0.54 P_prune=0.46 A_grow=0.19 A_prune=0.21\n",
            "Iteration  260/1100 P_grow=0.53 P_prune=0.47 A_grow=0.19 A_prune=0.21\n",
            "Iteration  270/1100 P_grow=0.53 P_prune=0.47 A_grow=0.17 A_prune=0.21\n",
            "Iteration  280/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.21\n",
            "Iteration  290/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.20\n",
            "Iteration  300/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.19\n",
            "Iteration  310/1100 P_grow=0.53 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  320/1100 P_grow=0.54 P_prune=0.46 A_grow=0.18 A_prune=0.21\n",
            "Iteration  330/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  340/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.20\n",
            "Iteration  350/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.20\n",
            "Iteration  360/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  370/1100 P_grow=0.53 P_prune=0.47 A_grow=0.17 A_prune=0.19\n",
            "Iteration  380/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  390/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.20\n",
            "Iteration  400/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  410/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  420/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  430/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.20\n",
            "Iteration  440/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.19\n",
            "Iteration  450/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.18\n",
            "Iteration  460/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.18\n",
            "Iteration  470/1100 P_grow=0.54 P_prune=0.46 A_grow=0.17 A_prune=0.18\n",
            "Iteration  480/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.19\n",
            "Iteration  490/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.19\n",
            "Iteration  500/1100 P_grow=0.55 P_prune=0.45 A_grow=0.16 A_prune=0.19\n",
            "Iteration  510/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.19\n",
            "Iteration  520/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.19\n",
            "Iteration  530/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.18\n",
            "Iteration  540/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.18\n",
            "Iteration  550/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.18\n",
            "Iteration  560/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  570/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.19\n",
            "Iteration  580/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.19\n",
            "Iteration  590/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  600/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.18\n",
            "Iteration  610/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.18\n",
            "Iteration  620/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  630/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.19\n",
            "Iteration  640/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.17\n",
            "Iteration  650/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.17\n",
            "Iteration  660/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.19\n",
            "Iteration  670/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.18\n",
            "Iteration  680/1100 P_grow=0.54 P_prune=0.46 A_grow=0.16 A_prune=0.17\n",
            "Iteration  690/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  700/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.18\n",
            "Iteration  710/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  720/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  730/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration  740/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.18\n",
            "Iteration  750/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.17\n",
            "Iteration  760/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.17\n",
            "Iteration  770/1100 P_grow=0.55 P_prune=0.45 A_grow=0.15 A_prune=0.18\n",
            "Iteration  780/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.18\n",
            "Iteration  790/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  800/1100 P_grow=0.53 P_prune=0.47 A_grow=0.16 A_prune=0.16\n",
            "Iteration  810/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  820/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  830/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.18\n",
            "Iteration  840/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  850/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.18\n",
            "Iteration  860/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.16\n",
            "Iteration  870/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.16\n",
            "Iteration  880/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  890/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration  900/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration  910/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration  920/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.16\n",
            "Iteration  930/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.16\n",
            "Iteration  940/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration  950/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration  960/1100 P_grow=0.52 P_prune=0.47 A_grow=0.14 A_prune=0.17\n",
            "Iteration  970/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.17\n",
            "Iteration  980/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.18\n",
            "Iteration  990/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration 1000/1100 P_grow=0.53 P_prune=0.47 A_grow=0.14 A_prune=0.17\n",
            "Iteration 1010/1100 P_grow=0.53 P_prune=0.47 A_grow=0.15 A_prune=0.17\n",
            "Iteration 1020/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.18\n",
            "Iteration 1030/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.16\n",
            "Iteration 1040/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.17\n",
            "Iteration 1050/1100 P_grow=0.52 P_prune=0.48 A_grow=0.14 A_prune=0.17\n",
            "Iteration 1060/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.16\n",
            "Iteration 1070/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.16\n",
            "Iteration 1080/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.16\n",
            "Iteration 1090/1100 P_grow=0.54 P_prune=0.46 A_grow=0.15 A_prune=0.17\n",
            "Iteration 1100/1100 P_grow=0.54 P_prune=0.46 A_grow=0.14 A_prune=0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of the printout:\n",
        "* P_grow = fraction of trees where a GROW move was proposed\n",
        "* A_grow = GROW acceptance: fraction of proposed GROW moves that were accepted\n",
        "* P_prune, A_prune = the same for the PRUNE move\n",
        "\n",
        "The fractions refer to the state of the trees at a single point in time, they are not averaged over multiple iterations.\n",
        "\n",
        "A low acceptance means that the trees are changing very slowly."
      ],
      "metadata": {
        "id": "BpyizlIjMeCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell computes the predictions."
      ],
      "metadata": {
        "id": "ra9xOl3YNY2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute predictions\n",
        "yhat_test = bart.predict(data.X_test) # posterior samples, n_samples x n_test\n",
        "yhat_test_mean = jnp.mean(yhat_test, axis=0) # posterior mean point-by-point\n",
        "yhat_test_var = jnp.var(yhat_test, axis=0) # posterior variance point-by-point\n",
        "\n",
        "# RMSE\n",
        "rmse = jnp.sqrt(jnp.mean(jnp.square(yhat_test_mean - data.y_test)))\n",
        "expected_error_variance = jnp.mean(jnp.square(bart.sigma))\n",
        "expected_rmse = jnp.sqrt(jnp.mean(yhat_test_var + expected_error_variance))\n",
        "avg_sigma = jnp.sqrt(expected_error_variance)\n",
        "\n",
        "print(f'total sdev: {jnp.std(data.y_train):#.2g}')\n",
        "print(f'error sdev: {sigma:#.2g}')\n",
        "print(f'RMSE: {rmse:#.2g}')\n",
        "print(f'expected RMSE: {expected_rmse:#.2g}')\n",
        "print(f'model error sdev: {avg_sigma:#.2g}')\n",
        "print(f'time: {(end - start) / 60:#.2g} min')"
      ],
      "metadata": {
        "id": "W2v-A58BNbuX",
        "outputId": "22ce2122-8c2b-4070-f55c-64c112725447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total sdev: 1.4\n",
            "error sdev: 0.10\n",
            "RMSE: 0.29\n",
            "expected RMSE: 0.28\n",
            "model error sdev: 0.23\n",
            "time: 6.0 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE can at best be as low as the error standard deviation used to generate the data."
      ],
      "metadata": {
        "id": "QigclpPkOVJq"
      }
    }
  ]
}